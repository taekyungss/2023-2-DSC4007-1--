{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chatbot\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "# llm\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "import os\n",
    "import gradio as gr\n",
    "import os\n",
    "\n",
    "api_key ='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' \n",
    "chat_model = ChatOpenAI(openai_api_key=api_key,temperature=0.8, model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ì´ë¦„</th>\n",
       "      <th>ì£¼ë¯¼ë“±ë¡ìƒ</th>\n",
       "      <th>ë¬¸ì œ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ê¹€íƒœê²½</td>\n",
       "      <td>í˜¼ì</td>\n",
       "      <td>ê±´ê°•ë³´í—˜ë£Œ ì—°ì²´</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ì£¼ì˜ˆì„œ</td>\n",
       "      <td>í˜¼ì</td>\n",
       "      <td>ì˜ë£Œë¹„ í•„ìš”</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ì´ë¦„ ì£¼ë¯¼ë“±ë¡ìƒ        ë¬¸ì œ\n",
       "0  ê¹€íƒœê²½    í˜¼ì  ê±´ê°•ë³´í—˜ë£Œ ì—°ì²´\n",
       "1  ì£¼ì˜ˆì„œ    í˜¼ì    ì˜ë£Œë¹„ í•„ìš”"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"data.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7870\n",
      "Running on public URL: https://413a879142bb0d7a94.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://413a879142bb0d7a94.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_template = f\"\"\"í•„ìˆ˜ : í•œë²ˆì˜ ë‹µë³€ì— í•œê°€ì§€ ì§ˆë¬¸ë§Œ í•œë‹¤. ì—¬ëŸ¬ê°€ì§€ ì§ˆë¬¸í•˜ì§€ ì•ŠëŠ”ë‹¤. ì£¼ë¡œ ë…¸ì¸ë¶„ë“¤ì„ ë‹´ë‹¹í•˜ëŠ” ë³µì§€ìƒë‹´ì„ ì§„í–‰í•œë‹¤. ê³µì†í•˜ê³  ì˜ˆì˜ë°”ë¥´ê²Œ ë§ì„ í•´ì•¼í•œë‹¤. ì „í™”í†µí™”ë¥¼ í•˜ëŠ” ê²ƒì²˜ëŸ¼ ëŒ€í™”ë¥¼ í•´ì•¼í•œë‹¤. \n",
    "\n",
    "0. ìƒëŒ€ë°©ì´ í•œ ë§ì„ ë°˜ë³µí•˜ì§€ ì•ŠëŠ”ë‹¤. íë¦„ì— ë§ê²Œ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ ì´ì–´ë‚˜ê°„ë‹¤.\n",
    "\n",
    "1. ì²˜ìŒ ë‹µë³€ì€ ì¸ì‚¬ë§ë¡œ ë³µì§€ ìƒë‹´ì„¼í„°ì„ì„ ì•Œë¦¬ê³  ì´ì–´ì„œ ìƒëŒ€ë°©ì˜ ë¬¸ì œ ìƒí™©ì€ \"{data[\"ë¬¸ì œ\"][0]}\" ì´ë¯€ë¡œ ë¬¸ì œ ìƒí™©ì„ í™•ì¸í•˜ê¸° ìœ„í•´ ì „í™”ë¥¼ ê±¸ì—ˆë‹¤ê³  ì¹œì ˆí•˜ê²Œ ë§í•˜ë©° ì‚¬ì‹¤ì¸ì§€ í™•ì¸í•œë‹¤. ì¸ì‚¬ëŠ” 1ë²ˆë§Œ í•œë‹¤.\n",
    "\n",
    "2. ìƒëŒ€ë°©ì˜ ì´ë¦„ì€ {data[\"ì´ë¦„\"][0]}ì´ë‹¤. í•´ë‹¹ ì´ë¦„ìœ¼ë¡œ ë¶€ë¥´ë©° ëŒ€í™”ë¥¼ í•œë‹¤.\n",
    "\n",
    "3. ë‹µë³€ì€ 2ì¤„ì´ë‚´ë¡œ ì§„í–‰í•œë‹¤. \n",
    "\n",
    "4. í•œêµ­ì–´ë¥¼ ì‚¬ìš©í•´ì„œ ëŒ€í™”í•œë‹¤.\n",
    "\n",
    "5. ë³¸ì¸ì´ ë§ì„ ê²½ìš° ìì—°ìŠ¤ëŸ½ê²Œ ì•„í”ˆ ê³³ì€ ì—†ëŠ”ì§€ ì•ˆë¶€ë¥¼ ë¬»ëŠ”ë‹¤.\n",
    "\n",
    "6. ê±´ê°•ì— ëŒ€í•œ ëŒ€ë‹µì„ ì´ìš©í•˜ì—¬ ì§§ì€ ëŒ€í™”ë¥¼ ë‚˜ëˆˆë‹¤.\n",
    "\n",
    "7. ê±´ê°•ì— ëŒ€í•œ ì—¼ë ¤ì™€ ê±±ì •ì„ í•˜ë©° ì•„í”Œ ë•Œ ë„ì›€ì„ ì¤„ ë°°ìš°ìë‚˜ ìë…€ê°€ ìˆëŠ”ì§€ ë¬»ëŠ”ë‹¤.\n",
    "\n",
    "8. ë„ì™€ì¤„ ì‚¬ëŒì´ ì—†ë‹¤ëŠ”ê±´ ìœ„í—˜ì— ë…¸ì¶œ ë˜ì–´ìˆë‹¤ëŠ” ëœ»ì´ë¯€ë¡œ ì–´ë– í•œ ì¡°ì¹˜ê°€ í•„ìš”í•˜ë‹¤.\n",
    "\n",
    "9. {data[\"ë¬¸ì œ\"][0]} ì¸ ìƒí™©ì„ ì–¸ê¸‰í•˜ë©° í˜„ì¬ ê·¼ë¡œ í™œë™ì— ëŒ€í•´ ë¬»ëŠ”ë‹¤.\n",
    "\n",
    "10. ì›” ìˆ˜ì…ì´ ì–´ëŠì •ë„ ì¸ì§€ ë¬»ëŠ”ë‹¤.\n",
    "\n",
    "11. í•œ ë‹µë³€ì— ì§ˆë¬¸ì€ ì˜¤ì§ í•œê°€ì§€ë§Œ í•œë‹¤. í•œ ì§ˆë¬¸ì— ëŒ€í•œ ëŒ€ë‹µì„ ë“£ê³  ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì„œ ë‹¤ìŒ ì§ˆë¬¸ì„í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ì§„í–‰í•œë‹¤.\n",
    "\n",
    "12. ë³‘ì› ì•½ ê°’ì´ë‚˜ ì§„ë£Œë¹„ë¥¼ ì§€ê¸ˆë³´ë‹¤ ëŒ€í­ ì¸í•˜ëœ ê¸ˆì•¡ìœ¼ë¡œ ì´ìš© ê°€ëŠ¥í•œ \"ì°¨ìƒìœ„ ë³¸ì¸ ë¶€ë‹´ ê²½ê°\"ì´ë¼ëŠ” ì œë„ê°€ ìˆë‹¤.\n",
    "\n",
    "13. ì›” ìˆ˜ì…ì´ 150ë§Œì› ì´í•˜ì´ë©´ \"ì°¨ìƒìœ„ ë³¸ì¸ ë¶€ë‹´ ê²½ê°\" ì œë„ì— ì‹ ì²­í•  ìˆ˜ ìˆë‹¤.\n",
    "\n",
    "14. ì‹ ì²­ì„ ì›í•˜ëŠ”ì§€ ë¬»ê³  ì›í•œë‹¤ë©´ ì¼ì • í™•ì¸ í›„ ìƒë‹´ ì˜ˆì•½ì„ ë°›ì€ ë’¤ ëŒ€í™”ë¥¼ ì¢…ë£Œí•œë‹¤.\n",
    "\n",
    "15. ëŒ€ë‹µí•˜ê¸° í¸í•œ ê°œë°©í˜• ì§ˆë¬¸í•˜ê¸°. \"\"\"\n",
    "\n",
    "chat_ai  = ChatOpenAI(openai_api_key=api_key,temperature=0.5, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "def response(message, history):  ## human, ai ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ìœ¼ë¡œ ì§€ì •\n",
    "    # ì¢…ë£Œí•˜ê² ìŠµë‹ˆë‹¤ë¥¼ ì…ë ¥í•˜ë©´ ìµœì¢… ìš”ì•½ ì¶œë ¥\n",
    "    if message == \"ì¢…ë£Œí•˜ê² ìŠµë‹ˆë‹¤\":\n",
    "        return summarize(history)\n",
    "\n",
    "    history_langchain_format = []\n",
    "    # í”„ë¡¬í”„íŠ¸ ì¶”ê°€\n",
    "    history_langchain_format.append(SystemMessage(content=chat_template))\n",
    "    # ì´ì „ ëŒ€í™” ê¸°ì–µ\n",
    "    for human, ai in history:\n",
    "        history_langchain_format.append(HumanMessage(content=human))\n",
    "        history_langchain_format.append(AIMessage(content=ai))\n",
    "    history_langchain_format.append(HumanMessage(content=message))\n",
    "    gpt_response = chat_ai(history_langchain_format)\n",
    "    return gpt_response.content\n",
    "\n",
    "\n",
    "# ìš”ì•½ llm ëª¨ë¸ ì¶”ê°€\n",
    "# summarize_llmê³¼ historyë¡œ ì¶œë ¥\n",
    "def summarize(history):\n",
    "    for i, (human, ai) in enumerate(history):\n",
    "        history[i] = (f\"ì‚¬ìš©ì : {human}\", f\"AI : {ai}\")\n",
    "\n",
    "    summarize_llm = OpenAI(\n",
    "        temperature=0.3, model=\"gpt-3.5-turbo-instruct\", max_tokens=512\n",
    "    )\n",
    "\n",
    "    summarize_template = \"\"\"\n",
    "    í•„ìˆ˜ : AIì™€ ì‚¬ìš©ì ëª¨ë‘ì˜ ëŒ€í™”ë¥¼ í•©ì³ì„œ ìš”ì•½í• ê±°ì•¼.\n",
    "    \n",
    "    0. ì‚¬ìš©ìì˜ ë¬¸ì œìƒí™©ì´ ë­”ì§€ ì •í™•í•˜ê²Œ íŒŒì•…í•˜ê³  ìš”ì•½í•´ì•¼í•´.\n",
    "\n",
    "    {texts} ëŒ€í™”ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ìš”ì•½ë¬¸ ì‘ì„±í•´ì¤˜.\n",
    "    \"\"\"\n",
    "\n",
    "    summarize_prompt = PromptTemplate(\n",
    "        template=summarize_template, input_variables=[\"texts\"]\n",
    "    )\n",
    "    summarize_chain = LLMChain(prompt=summarize_prompt, llm=summarize_llm)\n",
    "\n",
    "    return summarize_chain.run(history)\n",
    "\n",
    "\n",
    "gr.ChatInterface(\n",
    "    fn=response,\n",
    "    textbox=gr.Textbox(placeholder=\"ë§ê±¸ì–´ì£¼ì„¸ìš”..\", container=False, scale=7),\n",
    "    # ì±„íŒ…ì°½ì˜ í¬ê¸°ë¥¼ ì¡°ì ˆí•œë‹¤.\n",
    "    chatbot=gr.Chatbot(height=1000),\n",
    "    title=\"ì•„ì´(ìœ™ìœ™ì´)\",\n",
    "    description='ëŒ€í™”ê°€ ëë‚˜ë©´ \"ëŒ€í™”ì¢…ë£Œ\" ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”',\n",
    "    theme=\"soft\",\n",
    "    retry_btn=\"ë‹¤ì‹œë³´ë‚´ê¸° â†©\",\n",
    "    undo_btn=\"ì´ì „ì±— ì‚­ì œ âŒ\",\n",
    "    clear_btn=\"ì „ì±— ì‚­ì œ ğŸ’«\",\n",
    ").launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "qa, scoring-kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì§€ê¸ˆ í•˜ëŠ”ê±¸ ì™œ ì§€í”¼í‹° ì—ì´í”¼ì•„ì´ë¡œ í•´ì•¼í•˜ëŠ”ì§€\n",
    "ì„œë¨¸ë¼ì´ì¦ˆë¥¼ ì˜í•˜ê¸° ë–„ë¬¸\n",
    "-ì–´ëŠì–´ëŠ ì§€í‘œê°€ ë‚˜ì™”ê³  ìš°ë¦¬í•œí…Œë„ ì–´ë–¤ ì„±ëŠ¥ì´ ë‚˜ì™”ë‹¤.\n",
    "\n",
    "í”„ë¡¬í”„íŠ¸ì—”ì§€ë‹ˆì–´ë§ì—ì„œ ì§€í”¼í‹°ë¥¼ ì¨ë³¸ ê·¼ê±° - ì„¤ë“ë ¥\n",
    "íì—ì´ë‘ ì„œë¨¸ë¼ì´ì œì´ì…˜ ì™œ í–ˆëŠ”ì§€ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<í…ŒìŠ¤íŒ…>\n",
    "í”„ë¡¬í”„íŠ¸ì—”ì§€ë‹ˆì–´ë§ - ì„±ëŠ¥ì§€í‘œ\n",
    "ì •ì„±ì  / ì •ëŸ‰ì \n",
    "- (ì •ì„±ì ) 10ê°€ì§€ ì‹œë‚˜ë¦¬ì˜¤ ì¤‘ ..\n",
    "íì—ì´, ì„œë¨¸ë¼ì´ì œì´ì…˜ "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fcacde32bb32c0469f9d34927e3672fd6d24508167c7a053d60e64e40f375a83"
  },
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "gpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
